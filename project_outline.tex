\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{apacite}
\usepackage{caption}
\begin{document}

\author{
  Jonsson, Haukur\\
  \texttt{11137304}
  \and
  Rajamanickam, Santhosh\\
  \texttt{11650702}
  \and
  Rapp, Max\\
  \texttt{11404310}
}
\title{A Theory Learning SAT-Solver for Sudokus\\
	\large Project Report}
\maketitle



\section{Introduction}

%Due to the expressiveness of propositional logic, SAT-solvers allow the automated solution of a great variety of problems. Although the SAT-problem is the paradigmatic NP-complete problem typical complexity of SAT-problems is usually benign. In addition, recent years have seen an immense improvement in the efficiency of SAT-solvers. Thus it is no possible to use SAT-solvers to tackle problems whose conjunctive normal form (CNF) encodings involve hundreds of thousands of variables.%

%A much smaller problem commonly found for entertainment in newspapers or magazines are Sudoku riddles.%
Sudokus are commonly studied paradigm for SAT-solvers as well as constraint programming. Constraint programming sacrifices generality for efficiency by  tailoring solvers for hard problems using various constraints that go beyond the mere axioms of propositional logic. A common approach in constraint programming are ``Satisfiablity-Modulo-Theories"(SMT)-solvers. They supplement a SAT-solver by a specialised theory(T)-solver exploiting both the high degree of optimization of SAT-solvers and the domain specific efficiency of T-solvers.

For example in the DPLL(T)-algorithm a DPLL-based procedure is used to SAT-check a formula $F$ starting from an empty T-box. If the formula is satisfiable it is passed to a specialised T-solver that checks whether it is T-consistent. If not, $\neg F$ is added to the SAT-solver's axioms and so forth.

Both SAT and SMT approaches have their merits: SAT is a very general approach that requires minimal Human preprocessing while SMT can be much more efficient for specific domains.

In this report we investigate the middle ground between the two approaches for the domain of 9x9 Sudokus. Namely, we do not use a T-solver to add to the axioms but check the clauses learnt by the SAT-solver on specific Sudokus for global validity on Sudokus. If a valid clause is found, it is added to the axioms.

Based on previous results we hypothesize that in this way it is possible to train SAT-solvers to become more efficient on the current domain. We attempt to keep the procedure as general as possible so that it can be applied to any domain, not only Sudokus.

The rest of this report is organised as follows: the results of previous work that led us to our hypothesis are summarised in section \ref{related work}; we present our methodology including the choice of dataset, encodings, SAT-solver and performance metrics in section \ref{methods}; in section \ref{algorithm} we propose an algorithm for SAT-theory learning including clause pruning, validity checking and validity pruning and various training protocols; section \ref{results} summarizes our findings; finally, in section \ref{conclusion} we present our conclusions and suggest avenues for further research.

\section{Preliminaries}

Given a set of propositional variables, we call the variables and their negations $literals$. A $clause$ $s$ is a set of literals interpreted as a disjunction. We call a set $S$ of clauses interpreted as a conjunction a $SAT-problem$ (in CNF). A function $\phi$ that maps some problem to a $SAT-problem$ is called an $encoding$. As far as possible we will treat a SAT-solver as a blackbox that tells us whether a SAT-problem in CNF is satisfiable and returns a satisfying assignment of the propositional variables. A SAT-problem is $proper$ if it admits exactly one satisfying assignment. Given a set of SAT-problems $D=\{S_1,...,S_n\}$ with $\cap_{i=1}^n S_i\neq \emptyset$ in CNF we refer to $D$ as the $domain$ of the problem, $A=\cap_{i=1}^n S_i$ as the $axioms$ of $D$ and to  $C_i=S_i\setminus \cap_{i=1}^n S_i$ as the $claims$ or $assertions$ of problem $i$.
For $c\in C$, if the SAT-solver returns ``unsatisfiable" for $S=A\cup c$ we call $\neg c$ $valid$ and a $theorem$. An axiom $a\in A$ is $redundant$ iff it is a theorem for any domain $D_{\setminus a}$ with axioms $A_{\setminus a}=A\setminus a$. For any theorem, we call its minimal valid subclauses the $kernels$ of the theorem.

In this study $D_{min}$, $D_(eff)$, and $D_{ext}$ are the sets of proper SAT-problems obtained by appyling the corresponding encoding functions $\phi_{minimal}$, $\phi_{efficient}$ and $\phi_{extended}$ to a dataset of Sudokus to be specified below. The encodings furnish different sets of axioms $A_{min}$, $A_{eff}$ and $A_{ext}$. In addition, each individual SAT-problem is characterised by claims corresponding to the Sudoku's givens. We henceforth use Sudoku to refer to the SAT-problem corresponding to the Sudoku as well when the context is clear.



\section{Related Work} \label{related work}

Redundant axioms for Sudoku are mainly considered in constraint programming approaches. E.g. \citeA[11]{demoen2014redundant} find that: ``Redundant constraints are very often good for the performance of CP systems,
and indeed, all solvers we checked perform much slower (about a factor 2000) with
a minimal set of big constraints." \citeA{simonis2005sudoku} suggests several such redundant constraints and finds they boost performance of CP propagation schemes.

As opposed to CP-systems SAT-solvers usually only have very limited propagation schemes such as unit propagation. However, the literature on Sudoku as a SAT-problem considers redundant axioms from a different perspective. A large part of it is devoted to optimizing CNF-encodings for Sudoku with respect to SAT-solver performance. \citeA{sudokusat} suggest and test two encodings: a $minimal$ and an $extended$ encoding. The extended encoding is nothing else than an encoding containing redundant axioms. They compare the encodings efficiency
with respect to SAT-solvers' ability to solve Sudokus without search. They find among other things that substituting the minimal by the extended encoding increases the likelihood of solving a Sudoku without search using only unit propagation from 1\% to 69\%. In addition, \citeA{optimizedencoding} compared these encodings with respect to runtime over various Sudoku-sizes and found that the extended encoding scales much better with increased problem size.

This apparent convergence in two strains of literature led us to hypothesize that redundant axioms might be beneficial to SAT-solver performance in spite of their limited inference tools. We thus wanted to find out which redundant axioms would be most helpful in strengthening inference and minimizing search. One way to go about this is to look for redundant axioms that the SAT-solver actually $learns$ during the search process.



\section{Methodology} \label{methods}

We decided to test our hypothesis experimentally. In order to do this, it was necessary to choose a suitable dataset, SAT-solver and a meaningful metric of performance as well as a CNF-encoding of Sudoku.

\subsection{Dataset}
The domain of all proper Sudokus has a cardinality of more than $6.67*10^21$. Therefore it is necessary to work with a subdomain. We used the collection of minimum (i.e. 17 givens) proper sudokus assembled by Gordon Royle \cite{sudokudataset}.  A minimal Sudoku is a Sudoku from which no given can be removed leaving it a proper Sudoku. The dataset consists of 49151 such sudokus. %and is provided by the University of Western Australia. Refer this \cite{sudokudataset}to access the dataset.

We used 10000 sudokus to measure the performance of the SAT solver across different encodings and different base clauses. We used 5000 sudokus to train our SAT solver to learn new clauses which are valid for sudokus.

\subsection{Sudoku Encodings and DIMACS}

We use the three different types of encoding functions specified in \cite{sudokusat} and \cite{optimizedencoding} for our experiments: the minimal encoding , the efficient encoding , and the extended encoding.

%which are used to formulate Sudoku into a set of clauses. For more information refer \cite{sudokusat} and \cite{optimizedencoding}

%A given sudoku can be formulated as a SAT formula which is satisfiable if and only if the puzzle has a solution.
%Subsequently, the formula can be checked for satisfiability using SAT solver of our choice. A formula in CNF is represented by a set of clauses. The standard input format for most SAT solvers is CNF. Various encodings are known for encoding Sudoku as a CNF formula. We use three different types of encoding for our experiments which are: the minimal encoding , the efficient encoding , and the extended encoding which are used to formulate Sudoku into a set of clauses. For more information refer \cite{sudokusat} and \cite{optimizedencoding}

The difference in the encodings is their axioms. Namely, $A_{min}\subset A_{eff}\subset A_{ext}$. Since the minimal encoding is a complete axiomatization of Sudoku, all of the additional axioms in the other encodings are redundant.

%One advantage of avoiding redundancy in the axioms is that the size of the CNF-file produced can be significantly smaller. But according to our hypothesis we want to investigate the performance of the SAT-solvers when introducing interesting redundant clauses.

The encodings all have to encode the following four constraints:

\begin{itemize}
	\item each cell has to be filled with a number from 1-9
	\item each row must contain each number exactly once
	\item each column must constain each number exactly once
	\item each square block (eight on the edges, one in the center) of nine cells must contain each number exactly once
\end{itemize}

We follow \citeA{optimizedencoding} in representing them. The constraints are encoded using the same sets of propositional variables: in an $9\times 9$ Sudoku puzzle each cell must contain a number between 1 and 9. Thus, each cell is associated with 9 propositional variables which can be represented by 3-tuples $(r, c, v)$ as variables. %denote a variable which is true if and only if the cell in row $r$ and column $c$ is assigned a number $v$; i.e. $[r, c] = v$.
Then we get $V = \{(r, c, v)|1 \leq r, c, v \leq 9\}$ as the set of propositional variables

%Sudoku rules are represented as a set of clauses to guarantee that each row, column and block contains only one instance of each number from 1 to n.

The difference in the encodings stems from the way they encode the constraints. The following conjunctions refer to each cell, row, column or block having at least one number from 1 to n (i.e. $definedness$) or at most one number from 1 to n (i.e. $uniqueness$).
A subscript $d$ to denote definedness constraints and subscript $u$ to denote the uniqueness constraints. \\\\
$\begin{aligned}
Cell_{d} &= \bigwedge^{n}_{r=1}\bigwedge^{n}_{c=1}\bigwedge^{n}_{v=1} (r,c,v) &\\
Cell_{u} &= \bigwedge^{n}_{r=1}\bigwedge^{n}_{c=1}\bigwedge^{n-1}_{v_{i}=1} \bigvee^{n}_{v_{j}=v_{i}+1} \neg (r,c,v_{i}) \vee \neg (r,c,v_{j}) &\\
Row_{d} &= \bigwedge^{n}_{r=1}\bigwedge^{n}_{v=1}\bigvee^{n}_{c=1} (r,c,v) &\\
Row_{u} &= \bigwedge^{n}_{r=1}\bigwedge^{n}_{v=1}\bigwedge^{n-1}_{c_{i}=1} \bigwedge^{n}_{c_{j}=c_{i}+1} \neg (r,c_{i},v) \vee \neg (r,c_{j},v) &\\
Col_{d} &= \bigwedge^{n}_{c=1}\bigwedge^{n}_{v=1}\bigvee^{n}_{r=1} (r,c,v) &\\
Col_{u} &= \bigwedge^{n}_{c=1}\bigwedge^{n}_{v=1}\bigwedge^{n-1}_{r_{i}=1} \bigwedge^{n}_{r_{j}=r_{i}+1} \neg (r_{i},c,v) \vee \neg (r_{j},c,v) &\\
Block_{d} &= \bigwedge^{\sqrt{n}}_{r_{offs}=1}\bigwedge^{\sqrt{n}}_{c_{offs}=1}\bigwedge^{n}_{v=1}\bigvee_{r=1}^{\sqrt{n}}\bigvee_{c=1}^{\sqrt{n}}(r_{offs}*\sqrt{n}+r,c_{offs}*\sqrt{n}+c,v) &\\
Block_{d} &= \bigwedge^{\sqrt{n}}_{r_{offs}=1}\bigwedge^{\sqrt{n}}_{c_{offs}=1}\bigwedge^{n}_{v=1}\bigwedge_{r=1}^{n}\bigwedge_{c=r+1}^{n} &\\ & \neg (r_{offs}*\sqrt{n}+(r \space mod \sqrt{n}),c_{offs}*\sqrt{n}+(r \space mod \sqrt{n}),v) &\\
& \vee \neg (r_{offs}\sqrt{n}+(r \space mod \sqrt{n}),c_{offs}*\sqrt{n}(c \space mod \sqrt{n}),v)
\end{aligned}$

In addition one more conjunction is needed to represent givens. Each given contains a pre-assigned number and thus the givens form a conjunction of unit clauses.
%for example, if $[1,3] = 6$ in the input puzzle, then the cell $[1,3]$ is a given containing number $6$. %Let $V^{+}$ = \{$(r, c, v) \in V [r, c]\}$  be a given with pre-assigned value $v$} be a set of variables representing fixed cells and $k$ be the number of such fixed cells.
Let $G_i=\{(r_1,c_1,v_1),...,(r_k,c_k,v_k)\}$ be the set of givens of Sudoku $S_i$. Then we have: \\

$\begin{aligned}
Assigned &= \bigwedge^{k}_{i=1}(r,c,v),  where (r_j,c_j,v_j) \in G_i
\end{aligned}$

The differences in the three mentioned encodings then cosist in which of the definedness and uniqueness conditions they include \cite{optimizedencoding}: \\

$\begin{aligned}
\phi_{minimal} &= Cell_{d} \wedge Row_{u} \wedge Col_{u} \wedge Block_{u} \wedge Assigned &\\
\phi_{efficient} &= Cell_{d} \wedge Cell_{u} \wedge Row_{u} \wedge Col_{u} \wedge Block_{u} \wedge Assigned &\\
\phi_{extended} &= Cell_{d} \wedge Cell_{u} \wedge Row_{d} \wedge Row_{u} \wedge Col_{d} \wedge Col_{u} \wedge &\\
& Block_{d} \wedge Block_{u} \wedge Assigned &\\
\end{aligned}$ \\

%Hence we use the above encode to form the base clauses which are passed to the SAT solvers along with the given sudoku clauses. We use Python language to test our experiments and represent the clauses
Note that $\phi_minimal$ is a complete axiomatization of Sudoku and the additional axioms of the other encodings are thus redundant.

The encodings are represented in the DIMACS to pass them to the SAT-solver. It has the following format:\\\\
At the begining of the file there may be one or more comment lines. Comment lines start with a 'c'. They are followed by: \\

p FORMAT VARIABLES CLAUSES  \\

FORMAT is for programs to detect which format is to be expected. In our case this is ``cnf"

VARIABLES is the number of unique variables in the expression

CLAUSES is the number of clauses in the expression\\

This line is followed by the information in SAT-problem. Unique variables are enumerated from 1 to n. A negation is represented as '-'. Each line represents one disjunction and is delimited by ``0". Example: $(A \vee \neg B \vee C)\wedge(B \vee D \vee E)\wedge(D \vee F)$ is represented in DIMACS as: \\

c This is a comment

c This is another comment

p cnf 6 3

1 -2 3 0

2 4 5 0

4 6 0



\subsection{The Minisat-Solver}
The SAT-problems in DIMACS format are then passed on to a SAT-solver. For our experiment we use a SAT solver called Minisat. Minisat implements the DPLL algorithm and additionally implements conflict-driven learning and non-chronological backtracking. As Minisat has an upper limit on the number of learned clauses allowed it employs an activity heuristic when deciding which learned clauses to keep when it. The same heuristic is applied when doing backjumping. The heuristic essentially records which clauses and literals have been in recent conflicts and favors them over "stale" clauses and literals. For more information see (een2003extensible).

For our purposes we needed to record the learned clause for a given conflict. To do this we needed to edit the Minisat code such that when encountering a conflict the deduced learned clause is printed out. By printing out the learned clause straight away we avoided the upper limit of Minisat learned clauses.

\subsection{Performance Metric}

In additon we had Minisat output the number of $decisions$ per Sudoku. A decision consists in choosing a propositional variable and tentatively assigning it a truth value. The solver then checks whether the problem is satisfiable given the decision. Decisions occur when the SAT-solver exhausts its inference capabilities and resorts to search. Therefore the number of decisions is a good metric of the proportions of search vs inference the SAT-solver used in soving a SAT-problem. A low number of decisions indicates heavy use of inference, a high number indicates a lot of search.
Given our hypothesis that redundant axioms can help inference, we would expect the number of decisions to decrease when more redundant axioms are added.

%Overview:
%The project is about the effects of redundant constraints and the process of learning redundant constraints in Sudoku.

%Problem description:
%Definition: A redundant constraint is a constraint that is valid given the other constraints. That is, if A is a model for constraint/clause P(x,y), s.t. A |= P(x,y) with P'(x,y) =||= P(x,y) then A is also a model for Q(x,y,z)=P'(x,y)vR(z), that is, A |= Q(x,y,z). Q(x,y,z) is then a redundant clause.

%Many SAT solvers use clausal learning in the process of finding a model for the problem. Clausal learning adds clauses to the set of formulas. The clauses added do not affect the model of the problem but makes explicit which valuations are not possible. If the clause which is learned is valid given the original restraints (it is redundant), then it could have been derived to begin with and added to the set of formulas and the SAT solver would not have to explore the tree that lead to the learned clause. These redundant clauses become more important when dealing with a class of problems which differ only in few formulas. Learning clauses which pertain to the class of problems, not the individual problems, could save time as it reduces the search space and tells us more about the structure of the problem. In particular, it tells us what clauses could be added to the initial problem description and further speed up the SAT solver by adding redundant clauses (http://www.cs.cmu.edu/~hjain/papers/sudoku-as-SAT.pdf [Sudoku as SAT]).

%Checking validity of a clause is the VAL problem which is Co-NP. In other words, checking whether the negation is satisfiable will answer the VAL problem. If the negation of a clause is not satisfiable, the clause must be valid.

%Consider this example:
%Let's say the foreign policy of the country can be described by the following clauses:

%P'+Q'
%Q'+R'
%R+P

%In addition the king wants
%Q+R

%The first three clauses then describe the class of problem and the king's demands are a particular instance of the problem. When running a SAT solver on this problem it might try splitting by trying Q. Then we are forced to choose P' and R' but then we cannot satisfy R+P. The clauses of the class of problem imply Q'. We can therefore add Q' to the problem class description and avoid splitting by Q in future runs of another problem instance.

%Plan:
%Our plan is to explore the learned clauses when using a SAT solvers to solve Sudoku puzzles. More specifically, our plan is to find out which redundant constraints in Sudoku make SAT-solvers faster (here we should investigate the clauses from the extended encoding and also the constraints in http://4c.ucc.ie/~hsimonis/sudoku.pdf [Sudoku as constraint problem]) and especially we are interested in which of those redundant constraints are the most commonly learned.

%We look at two different encodings of Sudoku puzzles. One called the minimal encoding (a misnomer, see https://lirias.kuleuven.be/bitstream/123456789/353637/1/sudokutplp.pdf [redundant sudoku rules]) and the other one the extended encoding. Both are taken from http://www.cs.cmu.edu/~hjain/papers/sudoku-as-SAT.pdf [Sudoku as SAT]. Most results point towards faster execution of SAT solvers, given more redundant constaints. Except in the case when the redundant constraints overflow the memory of the machine running the SAT solver. In those cases a minimal representation of the problem might be more feasible. We therefore conjecture that:

%	"For low numbers of variables (e.g. 3x3 Sudokus) SAT-performance can be increased by adding redundant constraints.
%	For high numbers of variables (e.g. 81x81 Sudoku) SAT-performance suffers from adding redundant constraints."

%  "It is possible to train a SAT solver to perform faster on (a class of Sudokus) by letting it add the most commonly learned valid clauses to the constraints of the (class of) Sudokus."

%Data:
%As a data set I would suggest the 50000 minimal sudokus found here: http://staffhome.ecm.uwa.edu.au/~00013890/sudokumin.php
%Another dataset that might be useful is this website http://www.menneske.no/sudoku/
%This is also what's used in most of the other papers.

%Code:

%def generate_minimal_constraints(i,j,d):
  %constraints = []
  %constraints += valid_cells(i,j,d)
  %constraints += unique_rows(i,j,d)
  %constraints += unique_columns(i,j,d)
  %constraints += unique_blocks(i,j,d)

%def generate_minimal_constraints(i,j,d):
  %constraints = []
  %constraints += valid_cells(i,j,d)
  %constraints += unique_cells(i,j,d)
  %constraints += valid_rows(i,j,d)
  %constraints += unique_rows(i,j,d)
  %constraints += valid_columns(i,j,d)
  %constraints += unique_columns(i,j,d)
  %constraints += valid_blocks(i,j,d)
  %constraints += unique_blocks(i,j,d)

%def is_globally_valid(constraints, clause):
  %clause = negate_clause(clause)
  %results = solve_sudoku(constaints + clause)
  %if is_satisfied(results):
    %return True
  %return False


%constraints = generate_minimal_constraints()
%givens = read_givens() #from std.in
%results = solve_sudoku(constaints + givens)
%learned_clauses = read_from_results(results)
%globally_valid_clauses = []
%for learned_clause in learned_clauses:
  %if is_globally_valid(constraints, learned_clause):
    %globally_valid_clauses.append(learned_clause)

%print(globally_valid_clauses)
\section{The learning Algorithm} \label{algorithm}
The learning algorithm collects all learnt clauses reported by the SAT-solver, prunes the learnt clauses by removing clauses which are definitely not valid and then checks the validity of the remaining clauses. If a clause is found to be valid we add it to the encoding currently being run in order to avoid the the SAT-solver learning the same clause twice.

To test for validity of a clause we need check if the negation of that clause is not satisfiable with the encoding. If the negation is not satisfiable then the clause is valid.
\subsection{Clause Pruning} \label{clause pruning}
Since the number of learnt clauses can be very high for a single SAT-problem and we need to run a SAT-solver on each learnt clause it is important to remove clauses that we either know to be valid or not valid.

To detect valid clauses we check if the learnt clause is a superset of a clause in the extended encoding, i.e. clause in the encoding implies the learnt clause and therefore the learnt clause is valid. To detect a non-valid clause we first check if it is a unit clause, as they are never valid in sudokus. Secondly we check if the clause is not satisfied in any of our previous solutions, i.e. we check if we have a known counter-example to the clause. This step prunes the most number of clauses, is rather fast and gets better with runtime. Lastly, we check if the clause has length 9 or less and contains exactly one negated variable as these clauses are never valid in sudokus (proof omitted). The effectiveness of our pruning went from being able to prune away about 60% of the learnt clauses to about 90% over the runtime.

\subsection{Validity Pruning} \label{val pruning}
As the learnt clause is not necessarily the minimally valid clause w.r.t. sudokus and we don't want valid clauses which contain redundant variables to our encoding, we need to find the minimally valid clause. For the cases which we know the valid clause to be a superset of a clause in some encoding, we know that the minimal valid clause is exactly the clause in the encoding. For the cases in which the learnt clause is not a superset of any encoding we need to compute the minimally valid clause. Without going into too much detail about the algorithm which computes the minimally valid clause we simply state that it has a worst case factorial runtime with the number of variables in a clause as we attempt to construct a smaller clause with different combinations of variables, each of which needs to be checked for validity.
\subsection{Training} \label{training}
We ran our learning algorithm on 5000 sudokus which were not used when testing our encoding extended with learnt validities. After each 100 sudokus we gathered the learnt clauses and ran our learning algorithm on them and added the pruned validities to the current encoding.

\section{Results} \label{results}

Below are the results of the experiments conducted with just using the base clauses and using the learnt clauses obtained during the learning phase using the dataset mentioned in section(4.1)

\begin{center}
\captionof{table}{Number of Decisions made by SAT solver for dataset size = 10000} \label{tab:title}
\begin{tabular}{ | l | l | l |}
    \hline
     & Without using learnt clause & Using learnt clause \\ \hline
    Minimal & 4449142 & 4300697 \\ \hline
    Efficient & 4267712 & 4202448 \\ \hline
    Extended & 42134 & 42151 \\
    \hline
\end{tabular}
\end{center}

The results clearly indicate that the redundant axioms from the extended encoding yield an enormous decrease in the number of decisions: using the extended encoding the SAT-solver needs only about 1\% of the decisions it uses with the minimal or efficient encoding. This clearly shows that if the SAT-solver can learn axioms from the extended encoding, it should be possible to achieve a substantial decrease in the number of decisions.

\bigskip

The below table gives the results concerning the new clauses which are learnt during the training phase. We have categorized the results based on the type of the clause that is learnt which corresponds to the types of clauses explained in section(4.2)

\begin{center}
\captionof{table}{Number of clauses learnt in each category for dataset size = 5000} \label{tab:title}
\begin{tabular}{ | l | l | l | l | l | l | l | l | l | l |}
	\hline
     & $Block_{d}$ & $Row_{d}$ & $Col_{d}$ & $Cell_{d}$ & $Block_{u}$ & $Row_{u}$ & $Col_{u}$ & $Cell_{u}$ & New \\ \hline
    Minimal & 0 & 0 & 0 & 0 & 55 & 23 & 0 & 1358  & 7 \\ \hline
    Efficient & 0 & 0 & 0 & 0 & 53 & 25 & 0 & 509  & 3  \\ \hline
    Extended & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \hline
\end{tabular}
\end{center}
\bigskip

A decrease in decisions to the base case was not achieved. It is clearly visible that the SAT-solver was only able to learn clauses belonging to the minimal and efficient encodings. We hypothesize that the reason for this is that the length of axioms of type $Row_d$, $Col_d$, and $Block_d$ which characterise the extended encoding is much longer than those from the other encodings: $Row_d$, $Col_d$, and $Block_d$ axioms are nine-place disjunctions whereas $Cell_u$, $Row_u$, $Col_u$ and $Block_u$ are only two-place disjunctions. This makes it much harder for the SAT-solver to find extended encoding axioms.

The most interesting clauses that are learnt are that corresponds to the new column. These clauses do not fall into any of the previous category. Below are some new clauses learnt during the training in $(row, column, number)$ representation:

\begin{center}
Valid clauses learnt during training with minimal encoding
\end{center}
\[(9, 3, 8) \lor (2, 3, 8) \lor (4, 3, 8) \lor (8, 3, 8) \lor \neg (6, 3, 2) \lor (1, 3, 8) \lor (3, 3, 8) \lor (5, 3, 8) \lor \neg (7, 3, 9)\]
\[(9, 3, 8 ) \lor (2, 3, 8 ) \lor (8, 3, 8 ) \lor \neg (5, 1, 8 ) \lor (1, 3, 8 ) \lor (3, 3, 8 ) \lor \neg (7, 3, 9 ) \]
\[(9, 7, 4) \lor (8, 9, 4) \lor \neg (9, 8, 8) \lor \neg (9, 9, 1) \lor (8, 7, 4) \lor (8, 8, 4) \lor \neg (7, 4, 4)\] \\\\

The learnt clauses are of course very specific and to be able to make some sense of them, some generalization is needed. The first clause simply states that if some number $x$ and $y$ is in column $j$ and the number $z$ is missing from column $j$ then $z$ is where $x$ and $y$ are not. We observed a few of number of the clauses.

The second clause can then be interpreted as stating that when you a number $x$ in block $k$ and s.t. $x$ is not in column $j$ but column $j$ is a part of block $k$, then $x$ is somewhere in column $j$, excluding the cells that are in block $k$. It further states that if you have some other number $y$ in column $j$ - also excluding the cells that are in block $k$ - then $x$ is in some other place than $y$. In short this is stating that when a number is placed in some block then a column which is a part of the block, that number in that column needs to be from a different block as well as the fact that if a cell is filled in that column, the number cannot be in that cell.

The third clause is similar to the second clause but rather states that when a number is placed in a column which is a part of some block, the number in that block needs to be from a different column. We also found clauses which were like the second clause but exchanged row for column.

\section{Conclusion} \label{conclusion}


\bibliographystyle{apacite}
\bibliography{references}


\end{document}
